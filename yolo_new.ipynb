{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a45686b5-54c7-4ac1-a743-fa5e9cf3dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f360ce0e-bd4a-4147-a9fd-b46c320c09d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"data/train/images\"\n",
    "annotation_folder = \"data/train/labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1932497b-b680-4e79-8170-1319e410c180",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOdataset(Dataset):\n",
    "    def __init__(self, image_dir, annot_dir, S=4, B=2, C=20, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.annot_dir = annot_dir\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith(\".jpg\")]\n",
    "        self.S, self.B, self.C = S, B, C\n",
    "        self.transform = transform\n",
    "\n",
    "        self.classes = [\n",
    "            \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\",\n",
    "            \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "            \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\",\n",
    "            \"sheep\", \"sofa\", \"train\", \"tvmonitor\"\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_filename = self.image_files[idx]\n",
    "        image_path = os.path.join(self.image_dir, img_filename)\n",
    "        annot_path = os.path.join(self.annot_dir, img_filename.replace(\".jpg\", \".xml\"))\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        boxes, labels = self.parse_voc_xml(annot_path, image.size)\n",
    "        target = self.encode_target(boxes, labels)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, target\n",
    "\n",
    "    def parse_voc_xml(self, xml_path, image_size):\n",
    "        boxes, labels = [], []\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        w, h = image_size\n",
    "\n",
    "        for obj in root.findall(\"object\"):\n",
    "            label = obj.find(\"name\").text\n",
    "            xml_box = obj.find(\"bndbox\")\n",
    "            xmin = float(xml_box.find(\"xmin\").text)\n",
    "            ymin = float(xml_box.find(\"ymin\").text)\n",
    "            xmax = float(xml_box.find(\"xmax\").text)\n",
    "            ymax = float(xml_box.find(\"ymax\").text)\n",
    "\n",
    "            x_center = ((xmin + xmax) / 2) / w\n",
    "            y_center = ((ymin + ymax) / 2) / h\n",
    "            box_w = (xmax - xmin) / w\n",
    "            box_h = (ymax - ymin) / h\n",
    "\n",
    "            boxes.append([x_center, y_center, box_w, box_h])\n",
    "            labels.append(self.classes.index(label))\n",
    "        return boxes, labels\n",
    "\n",
    "    def encode_target(self, boxes, labels):\n",
    "        S, B, C = self.S, self.B, self.C\n",
    "        target = torch.zeros((S, S, C + 5 * B))\n",
    "\n",
    "        for box, label in zip(boxes, labels):\n",
    "            x, y, w, h = box\n",
    "            grid_x = min(int(S * x), S - 1)\n",
    "            grid_y = min(int(S * y), S - 1)\n",
    "            x_cell = S * x - grid_x\n",
    "            y_cell = S * y - grid_y\n",
    "\n",
    "            # fill first box\n",
    "            target[grid_y, grid_x, 0:5] = torch.tensor([x_cell, y_cell, w, h, 1])\n",
    "            # class one-hot\n",
    "            target[grid_y, grid_x, 5 * B + label] = 1\n",
    "\n",
    "        return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59bee7f9-8744-4424-ad58-743594606d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b6ed1db-cb85-4488-8096-a3042f8928d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "torch.Size([4, 4, 30])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = YOLOdataset(\n",
    "    image_dir=\"data/train/Images\",\n",
    "    annot_dir=\"data/train/labels\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = YOLOdataset(\n",
    "    image_dir=\"data/test/Images\",\n",
    "    annot_dir=\"data/test/labels\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "image, target = train_dataset[0]\n",
    "print(image.shape)  # [3, 224, 224]\n",
    "print(target.shape) # [4, 4, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58957316-830e-4842-9292-d6f182200b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size=4,shuffle=True,num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5be3670b-d127-43e5-bf31-c93975d6d0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch image shape: torch.Size([4, 3, 224, 224])\n",
      "Batch target shape: torch.Size([4, 4, 4, 30])\n"
     ]
    }
   ],
   "source": [
    "for imgs, targets in train_loader:\n",
    "    print(\"Batch image shape:\", imgs.shape)    # [batch_size, 3, 448, 448]\n",
    "    print(\"Batch target shape:\", targets.shape) # [batch_size, 7, 7, 30]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66a8d983-8476-4f00-8ec3-1199781ff57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloLoss(nn.Module):\n",
    "    def __init__(self, S=4, B=2, C=20, λ_coord=5, λ_noobj=0.5):\n",
    "        super(YoloLoss, self).__init__()\n",
    "        self.mse = nn.MSELoss(reduction=\"sum\")\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.lambda_coord = λ_coord\n",
    "        self.lambda_noobj = λ_noobj\n",
    "\n",
    "    def forward(self, predictions, target):\n",
    "        # reshape [N, S, S, C + 5B]\n",
    "        predictions = predictions.reshape(-1, self.S, self.S, self.C + self.B * 5)\n",
    "\n",
    "        # --- 1️⃣ CLASS LOSS ---\n",
    "        class_pred = predictions[..., :self.C]\n",
    "        class_target = target[..., self.B * 5:]\n",
    "        obj_mask = target[..., 4].unsqueeze(-1)  # only where object exists\n",
    "        class_loss = self.mse(obj_mask * class_pred, obj_mask * class_target)\n",
    "\n",
    "        # --- 2️⃣ COORDINATE LOSS ---\n",
    "        box_pred = predictions[..., self.C:self.C + 5]  # first box\n",
    "        box_target = target[..., 0:5]\n",
    "\n",
    "        # x, y loss\n",
    "        box_pred_xy = box_pred[..., 0:2]\n",
    "        box_target_xy = box_target[..., 0:2]\n",
    "        coord_loss_xy = self.mse(obj_mask * box_pred_xy, obj_mask * box_target_xy)\n",
    "\n",
    "        # w, h loss (sqrt)\n",
    "        box_pred_wh = torch.sign(box_pred[..., 2:4]) * torch.sqrt(torch.abs(box_pred[..., 2:4] + 1e-6))\n",
    "        box_target_wh = torch.sqrt(box_target[..., 2:4])\n",
    "        coord_loss_wh = self.mse(obj_mask * box_pred_wh, obj_mask * box_target_wh)\n",
    "\n",
    "        coord_loss = self.lambda_coord * (coord_loss_xy + coord_loss_wh)\n",
    "\n",
    "        # --- 3️⃣ OBJECT CONFIDENCE LOSS ---\n",
    "        conf_pred = box_pred[..., 4]\n",
    "        conf_target = box_target[..., 4]\n",
    "        obj_conf_loss = self.mse(obj_mask.squeeze(-1) * conf_pred, obj_mask.squeeze(-1) * conf_target)\n",
    "\n",
    "        # --- 4️⃣ NO OBJECT CONFIDENCE LOSS ---\n",
    "        noobj_mask = 1 - obj_mask\n",
    "        noobj_conf_loss = self.mse(noobj_mask.squeeze(-1) * conf_pred, noobj_mask.squeeze(-1) * conf_target)\n",
    "        noobj_conf_loss = self.lambda_noobj * noobj_conf_loss\n",
    "\n",
    "        # --- TOTAL LOSS ---\n",
    "        total_loss = coord_loss + obj_conf_loss + noobj_conf_loss + class_loss\n",
    "        return total_loss\n",
    "\n",
    "# Lekin YOLOv1 ka structure hota hai:\n",
    "# [..., C + 0: C + 5] → first bbox [x, y, w, h, conf]\n",
    "# [..., C + 5: C + 10] → second bbox [x, y, w, h, conf]\n",
    "# [..., :C] → class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5df9846f-9bde-4417-a204-8abb3b15235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = YoloLoss(S=4, B=2, C=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05726ca7-054f-4edc-8964-ad5be3d661f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO(nn.Module):\n",
    "    def __init__(self, B, C):\n",
    "        super().__init__()\n",
    "\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.S = 4\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(in_channels = 3, out_channels=64, kernel_size=7, stride=2, padding=3) #1\n",
    "        self.leaky1 = nn.LeakyReLU(0.1)\n",
    "        self.max_pool_1 = nn.MaxPool2d(kernel_size=2,stride=2, padding=0) #2\n",
    "\n",
    "        self.conv_2 = nn.Conv2d(in_channels=64, out_channels=192, kernel_size=3, stride=1, padding=1) #3\n",
    "        self.leaky2 = nn.LeakyReLU(0.1)\n",
    "        self.max_pool_2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) #4\n",
    "\n",
    "        self.conv_3 = nn.Conv2d(in_channels=192, out_channels=128, kernel_size=1, stride=1, padding=0) #5\n",
    "        self.leaky3 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv_4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1) #6\n",
    "        self.leaky4 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv_5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=1, stride=1, padding=0) #7\n",
    "        self.leaky5 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv_6 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1) #8\n",
    "        self.leaky6 = nn.LeakyReLU(0.1)\n",
    "        self.max_pool_3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) #9\n",
    "\n",
    "\n",
    "        # 10–17\n",
    "        self.conv_7 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=0) #10\n",
    "        self.leaky7 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv_8 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1) #11\n",
    "        self.leaky8 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv_9 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=0) #12\n",
    "        self.leaky9 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv_10 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1) #13\n",
    "        self.leaky10 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv_11 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=0) #14\n",
    "        self.leaky11 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv_12 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1) #15\n",
    "        self.leaky12 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv_13 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=0) #16\n",
    "        self.leaky13 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv_14 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1) #17\n",
    "        self.leaky14 = nn.LeakyReLU(0.1)\n",
    "        self.max_pool_4 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "\n",
    "\n",
    "        self.conv_15 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=1, stride=1, padding=0) #18\n",
    "        self.leaky15 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv_16 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1) #19\n",
    "        self.leaky16 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv_17 = nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1, stride=1, padding=0) #20\n",
    "        self.leaky17 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv_18 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1) #21\n",
    "        self.leaky18 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv_19 = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=1, padding=1) #22\n",
    "        self.leaky19 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv_20 = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=2, padding=1) #23\n",
    "        self.leaky20 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv_21 = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=1, padding=1) #24\n",
    "        self.leaky21 = nn.LeakyReLU(0.1)\n",
    "\n",
    "\n",
    "\n",
    "        # self.fc1 = nn.Linear(in_features=3*3*1024, out_features=4096)\n",
    "        # self.leaky22 = nn.LeakyReLU(0.1)\n",
    "        # self.fc2 = nn.Linear(4096, 3*3*(self.B*5 + self.C))\n",
    "\n",
    "        # self.fc1 = nn.Linear(in_features=self.S*self.S*1024, out_features=4096)\n",
    "        self.fc1 = nn.Linear(1024 * self.S * self.S, 4096)\n",
    "        self.leaky22 = nn.LeakyReLU(0.1)\n",
    "        self.fc2 = nn.Linear(4096, self.S*self.S*(self.B*5 + self.C))\n",
    "\n",
    "        # B = 2 (bounding boxes per grid cell)\n",
    "        # C = 20 (for Pascal VOC 20 classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out1 = self.leaky1(self.conv_1(x))\n",
    "        out2 = self.max_pool_1(out1)\n",
    "        \n",
    "        out3 = self.leaky2(self.conv_2(out2))\n",
    "        out4 = self.max_pool_2(out3)\n",
    "        \n",
    "        out5 = self.leaky3(self.conv_3(out4))\n",
    "        out6 = self.leaky4(self.conv_4(out5))\n",
    "        out7 = self.leaky5(self.conv_5(out6))\n",
    "        out8 = self.leaky6(self.conv_6(out7))\n",
    "        out9 = self.max_pool_3(out8)\n",
    "        out10 = self.leaky7(self.conv_7(out9))\n",
    "        out11 = self.leaky8(self.conv_8(out10))\n",
    "        out12 = self.leaky9(self.conv_9(out11))\n",
    "        out13 = self.leaky10(self.conv_10(out12))\n",
    "        out14 = self.leaky11(self.conv_11(out13))\n",
    "        out15 = self.leaky12(self.conv_12(out14))\n",
    "        out16 = self.leaky13(self.conv_13(out15))\n",
    "        out17 = self.leaky14(self.conv_14(out16))\n",
    "        out18 = self.max_pool_4(out17)\n",
    "        out19 = self.leaky15(self.conv_15(out18))\n",
    "        out20 = self.leaky16(self.conv_16(out19))\n",
    "        out21 = self.leaky17(self.conv_17(out20))\n",
    "        out22 = self.leaky18(self.conv_18(out21))\n",
    "        out23 = self.leaky19(self.conv_19(out22))\n",
    "        out24 = self.leaky20(self.conv_20(out23))\n",
    "        out25 = self.leaky21(self.conv_21(out24))\n",
    "        \n",
    "        out26 = out25.view(out25.size(0), -1)\n",
    "        out27 = self.leaky22(self.fc1(out26))\n",
    "        out28 = self.dropout(out27)\n",
    "        out29 = self.fc2(out28)\n",
    "        out29 = out29.view(-1, self.S, self.S, self.C + 5*self.B)\n",
    "        \n",
    "        return out29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d323ab52-c825-4848-92a9-5914bb829812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"  if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0228fc82-b529-488a-9356-b695653e77cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLO(\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (conv_1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (leaky1): LeakyReLU(negative_slope=0.1)\n",
       "  (max_pool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_2): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (leaky2): LeakyReLU(negative_slope=0.1)\n",
       "  (max_pool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_3): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (leaky3): LeakyReLU(negative_slope=0.1)\n",
       "  (conv_4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (leaky4): LeakyReLU(negative_slope=0.1)\n",
       "  (conv_5): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (leaky5): LeakyReLU(negative_slope=0.1)\n",
       "  (conv_6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (leaky6): LeakyReLU(negative_slope=0.1)\n",
       "  (max_pool_3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_7): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (leaky7): LeakyReLU(negative_slope=0.1)\n",
       "  (conv_8): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (leaky8): LeakyReLU(negative_slope=0.1)\n",
       "  (conv_9): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (leaky9): LeakyReLU(negative_slope=0.1)\n",
       "  (conv_10): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (leaky10): LeakyReLU(negative_slope=0.1)\n",
       "  (conv_11): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (leaky11): LeakyReLU(negative_slope=0.1)\n",
       "  (conv_12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (leaky12): LeakyReLU(negative_slope=0.1)\n",
       "  (conv_13): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (leaky13): LeakyReLU(negative_slope=0.1)\n",
       "  (conv_14): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (leaky14): LeakyReLU(negative_slope=0.1)\n",
       "  (max_pool_4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_15): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (leaky15): LeakyReLU(negative_slope=0.1)\n",
       "  (conv_16): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (leaky16): LeakyReLU(negative_slope=0.1)\n",
       "  (conv_17): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (leaky17): LeakyReLU(negative_slope=0.1)\n",
       "  (conv_18): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (leaky18): LeakyReLU(negative_slope=0.1)\n",
       "  (conv_19): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (leaky19): LeakyReLU(negative_slope=0.1)\n",
       "  (conv_20): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (leaky20): LeakyReLU(negative_slope=0.1)\n",
       "  (conv_21): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (leaky21): LeakyReLU(negative_slope=0.1)\n",
       "  (fc1): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "  (leaky22): LeakyReLU(negative_slope=0.1)\n",
       "  (fc2): Linear(in_features=4096, out_features=480, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "# device = \"cpu\"\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = YOLO(B=2, C=20)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a069c86-f5d4-4c97-85fd-e6cb5ceec0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# optimizer = torch.optim.SGD(model.parameters(),lr=1e-2,momentum=0.9, weight_decay=0.0005)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f37bd964-488f-46f9-a977-3b108076d205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [135/200]: 100%|██████████████████████████████████████████████████| 5534/5534 [22:13<00:00,  4.15it/s, loss=15.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [135/200] | Avg Loss: 18.2605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [136/200]: 100%|██████████████████████████████████████████████████| 5534/5534 [20:03<00:00,  4.60it/s, loss=26.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [136/200] | Avg Loss: 18.2566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [137/200]: 100%|██████████████████████████████████████████████████| 5534/5534 [19:43<00:00,  4.67it/s, loss=8.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [137/200] | Avg Loss: 18.2649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [138/200]: 100%|██████████████████████████████████████████████████| 5534/5534 [20:07<00:00,  4.58it/s, loss=30.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [138/200] | Avg Loss: 18.2579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [139/200]: 100%|██████████████████████████████████████████████████| 5534/5534 [20:32<00:00,  4.49it/s, loss=21.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [139/200] | Avg Loss: 18.2628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [140/200]: 100%|██████████████████████████████████████████████████| 5534/5534 [20:37<00:00,  4.47it/s, loss=31.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [140/200] | Avg Loss: 18.2517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [141/200]: 100%|████████████████████████████████████████████████████| 5534/5534 [20:26<00:00,  4.51it/s, loss=15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [141/200] | Avg Loss: 18.2601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [142/200]: 100%|██████████████████████████████████████████████████| 5534/5534 [20:33<00:00,  4.49it/s, loss=36.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [142/200] | Avg Loss: 18.2561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [143/200]: 100%|██████████████████████████████████████████████████| 5534/5534 [20:25<00:00,  4.52it/s, loss=10.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [143/200] | Avg Loss: 18.2709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [144/200]: 100%|██████████████████████████████████████████████████| 5534/5534 [20:20<00:00,  4.53it/s, loss=38.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [144/200] | Avg Loss: 18.2539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [145/200]: 100%|██████████████████████████████████████████████████| 5534/5534 [20:22<00:00,  4.53it/s, loss=13.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [145/200] | Avg Loss: 18.2616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [146/200]: 100%|██████████████████████████████████████████████████| 5534/5534 [20:40<00:00,  4.46it/s, loss=24.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [146/200] | Avg Loss: 18.2460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [147/200]: 100%|██████████████████████████████████████████████████| 5534/5534 [20:34<00:00,  4.48it/s, loss=13.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [147/200] | Avg Loss: 18.2493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [148/200]: 100%|██████████████████████████████████████████████████| 5534/5534 [20:40<00:00,  4.46it/s, loss=19.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [148/200] | Avg Loss: 18.2557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [149/200]: 100%|██████████████████████████████████████████████████| 5534/5534 [20:42<00:00,  4.45it/s, loss=7.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [149/200] | Avg Loss: 18.2552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [150/200]: 100%|██████████████████████████████████████████████████| 5534/5534 [20:30<00:00,  4.50it/s, loss=17.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [150/200] | Avg Loss: 18.2626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [151/200]: 100%|██████████████████████████████████████████████████| 5534/5534 [20:37<00:00,  4.47it/s, loss=12.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [151/200] | Avg Loss: 18.2598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [152/200]: 100%|██████████████████████████████████████████████████| 5534/5534 [20:45<00:00,  4.44it/s, loss=7.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [152/200] | Avg Loss: 18.2526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [153/200]: 100%|████████████████████████████████████████████████████| 5534/5534 [20:44<00:00,  4.45it/s, loss=20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [153/200] | Avg Loss: 18.2539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [154/200]: 100%|██████████████████████████████████████████████████| 5534/5534 [20:44<00:00,  4.45it/s, loss=13.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [154/200] | Avg Loss: 18.2537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [155/200]:   3%|█▌                                                  | 172/5534 [00:36<19:09,  4.66it/s, loss=9.5]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 71\u001b[0m\n\u001b[0;32m     69\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     70\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 71\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     74\u001b[0m loop\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:140\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[0;32m    139\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    491\u001b[0m             )\n\u001b[1;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\adam.py:244\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    232\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    234\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    235\u001b[0m         group,\n\u001b[0;32m    236\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    241\u001b[0m         state_steps,\n\u001b[0;32m    242\u001b[0m     )\n\u001b[1;32m--> 244\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\adam.py:876\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    874\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 876\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\adam.py:685\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    682\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_foreach_addcdiv_(device_params, device_exp_avgs, exp_avg_sq_sqrt)\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    684\u001b[0m     bias_correction1 \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 685\u001b[0m         \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps\n\u001b[0;32m    686\u001b[0m     ]\n\u001b[0;32m    687\u001b[0m     bias_correction2 \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    688\u001b[0m         \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps\n\u001b[0;32m    689\u001b[0m     ]\n\u001b[0;32m    691\u001b[0m     step_size \u001b[38;5;241m=\u001b[39m _stack_if_compiling([(lr \u001b[38;5;241m/\u001b[39m bc) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bc \u001b[38;5;129;01min\u001b[39;00m bias_correction1])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:106\u001b[0m, in \u001b[0;36m_get_value\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m x\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==== CONFIG ====\n",
    "epochs = 200\n",
    "learning_rate = 1e-4\n",
    "save_checkpoint = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "img_scale = 224\n",
    "amp = False\n",
    "\n",
    "# ==== LOGGING SETUP ====\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "os.makedirs(\"detections\", exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_file = f\"logs/train_{timestamp}.log\"\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=log_file,\n",
    "    filemode='w',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s | %(levelname)s | %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "logging.info(f\"Starting training at {timestamp}\")\n",
    "logging.info(f\"Device: {device}\")\n",
    "\n",
    "# ==== MODEL / LOSS / OPTIMIZER ====\n",
    "model = YOLO(B=2, C=20).to(device)\n",
    "loss_fn = YoloLoss(S=4, B=2, C=20)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "\n",
    "# ==== CHECKPOINT HANDLING ====\n",
    "# checkpoint_path = \"checkpoints/best_model.pth\"\n",
    "checkpoint_path = \"checkpoints/last_checkpoint.pth\"\n",
    "best_loss = float('inf')\n",
    "start_epoch = 0\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_loss = checkpoint.get('best_loss', float('inf'))\n",
    "    logging.info(f\"✅ Resumed from epoch {start_epoch}, best loss so far: {best_loss:.4f}\")\n",
    "\n",
    "# ==== TRAINING LOOP ====\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    loop = tqdm(train_loader, total=len(train_loader), desc=f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "    for imgs, targets in loop:\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "\n",
    "        # forward\n",
    "        preds = model(imgs)\n",
    "        loss = loss_fn(preds, targets)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    scheduler.step()\n",
    "\n",
    "    # ==== LOGGING ====\n",
    "    logging.info(f\"Epoch [{epoch+1}/{epochs}] | Avg Loss: {avg_loss:.4f}\")\n",
    "    print(f\"✅ Epoch [{epoch+1}/{epochs}] | Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # ==== SAVE CHECKPOINT ====\n",
    "    if save_checkpoint:\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_loss': best_loss\n",
    "        }\n",
    "        torch.save(state, \"checkpoints/last_checkpoint.pth\")\n",
    "\n",
    "    # ==== SAVE BEST MODEL ====\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save(state, checkpoint_path)\n",
    "        logging.info(f\"💾 Saved Best Model at epoch {epoch+1} (Loss: {best_loss:.4f})\")\n",
    "\n",
    "    # ==== SAVE SAMPLE DETECTION ====\n",
    "    # model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     sample_img, _ = next(iter(val_loader))\n",
    "    #     sample_img = sample_img.to(device)\n",
    "    #     pred = model(sample_img)\n",
    "\n",
    "    #     # convert predictions to bounding boxes (you should have a decode function)\n",
    "    #     # boxes, labels, scores = decode_predictions(pred)\n",
    "\n",
    "    #     # visualize (placeholder example)\n",
    "    #     save_path = f\"detections/epoch_{epoch+1}.png\"\n",
    "    #     img_np = sample_img[0].permute(1,2,0).cpu().numpy()\n",
    "    #     plt.imshow(img_np)\n",
    "    #     plt.title(f\"Epoch {epoch+1} Predictions\")\n",
    "    #     plt.axis(\"off\")\n",
    "    #     plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    #     plt.close()\n",
    "    #     logging.info(f\"📸 Saved detection example at {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5116ea6f-056b-4de4-b073-1b357cc1c738",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42741ef4-3b40-42eb-a1c6-96fc34135979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
